#!/usr/bin/env python3
"""
main.py â€“ OCR a (range of) PDF pages using Alibaba DashScope's
Qwen-VL OCR model via the OpenAIâ€‘compatible endpoint.
Then use third-party Gemini service for text correction.

Env vars expected in .env (same directory):
  DASHSCOPE_API_KEY   â€“ your DashScope (Bailian) API key
  GEMINI_API_KEY      â€“ your Gemini API key
  GEMINI_BASE_URL     â€“ third-party Gemini service URL
"""

import base64
import io
import os
import sys
import tempfile
from pathlib import Path
from typing import List, Tuple, Dict, Any, Callable
from abc import ABC, abstractmethod

from dotenv import load_dotenv
from openai import OpenAI
from pdf2image import convert_from_path, exceptions as pdf_exc
from tqdm import tqdm
import pypdf

# ---------- 1. Dependency checking ----------
def check_dependencies():
    """æ£€æŸ¥æ‰€æœ‰ä¾èµ–é¡¹"""
    missing_deps = []
    
    # æ£€æŸ¥å¿…è¦çš„åŒ…
    try:
        import pdf2image
    except ImportError:
        missing_deps.append("pdf2image åŒ…æœªå®‰è£… (è¿è¡Œ: uv add pdf2image)")
    
    try:
        import pypdf
    except ImportError:
        missing_deps.append("pypdf åŒ…æœªå®‰è£… (è¿è¡Œ: uv add pypdf)")
    
    try:
        import openai
    except ImportError:
        missing_deps.append("openai åŒ…æœªå®‰è£… (è¿è¡Œ: uv add openai)")
    
    try:
        import google.generativeai
    except ImportError:
        missing_deps.append("google-generativeai åŒ…æœªå®‰è£… (è¿è¡Œ: uv add google-generativeai)")
    
    try:
        import tqdm
    except ImportError:
        missing_deps.append("tqdm åŒ…æœªå®‰è£… (è¿è¡Œ: uv add tqdm)")
    
    try:
        import dotenv
    except ImportError:
        missing_deps.append("python-dotenv åŒ…æœªå®‰è£… (è¿è¡Œ: uv add python-dotenv)")
    
    # æ£€æŸ¥poppler
    try:
        from pdf2image import convert_from_path
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„å°PDFæ¥æµ‹è¯•poppler
        test_path = Path(__file__).parent / "test_dummy.pdf"
        if not test_path.exists():
            # å¦‚æœæ²¡æœ‰æµ‹è¯•æ–‡ä»¶ï¼Œåªæ£€æŸ¥å¯¼å…¥æ˜¯å¦æˆåŠŸ
            pass
    except Exception as e:
        if "poppler" in str(e).lower() or "pdftoppm" in str(e).lower():
            missing_deps.append("Poppler æœªå®‰è£… (macOS: brew install poppler, Ubuntu: sudo apt install poppler-utils)")
    
    return missing_deps

def check_env_vars():
    """æ£€æŸ¥ç¯å¢ƒå˜é‡"""
    # å…ˆåŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv(Path(__file__).parent / ".env")
    
    missing_env = []
    warnings = []
    
    # è·å–æ‰€æœ‰ç¯å¢ƒå˜é‡
    DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY", "").strip()
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
    GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL", "").strip()
    MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "").strip()
    CUSTOM_OCR_API_KEY = os.getenv("CUSTOM_OCR_API_KEY", "").strip()
    CUSTOM_OCR_BASE_URL = os.getenv("CUSTOM_OCR_BASE_URL", "").strip()
    
    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    if not GEMINI_API_KEY:
        missing_env.append("GEMINI_API_KEY (æ–‡æœ¬çº é”™å¿…éœ€)")
    if not GEMINI_BASE_URL:
        missing_env.append("GEMINI_BASE_URL (æ–‡æœ¬çº é”™å¿…éœ€)")
    
    # æ£€æŸ¥OCRæœåŠ¡ (è‡³å°‘éœ€è¦ä¸€ä¸ª)
    available_ocr_services = 0
    if DASHSCOPE_API_KEY:
        available_ocr_services += 1
    if MISTRAL_API_KEY:
        available_ocr_services += 1
    if CUSTOM_OCR_API_KEY and CUSTOM_OCR_BASE_URL:
        available_ocr_services += 1
    
    if available_ocr_services == 0:
        missing_env.append("è‡³å°‘ä¸€ä¸ªOCRæœåŠ¡çš„APIå¯†é’¥ (DASHSCOPE_API_KEY, MISTRAL_API_KEY, æˆ– CUSTOM_OCR_API_KEY+CUSTOM_OCR_BASE_URL)")
    
    # æ·»åŠ é…ç½®æé†’
    if not DASHSCOPE_API_KEY:
        warnings.append("DashScope OCRæœåŠ¡æœªé…ç½®")
    if not MISTRAL_API_KEY:
        warnings.append("Mistral OCRæœåŠ¡æœªé…ç½®")
    if not (CUSTOM_OCR_API_KEY and CUSTOM_OCR_BASE_URL):
        warnings.append("è‡ªå®šä¹‰OCRæœåŠ¡æœªé…ç½®")
    
    return missing_env, warnings, {
        'dashscope': DASHSCOPE_API_KEY,
        'gemini_key': GEMINI_API_KEY,
        'gemini_url': GEMINI_BASE_URL,
        'mistral': MISTRAL_API_KEY,
        'custom_key': CUSTOM_OCR_API_KEY,
        'custom_url': CUSTOM_OCR_BASE_URL
    }

def auto_dependency_check():
    """è‡ªåŠ¨æ£€æŸ¥ä¾èµ–å¹¶ç»™å‡ºè§£å†³æ–¹æ¡ˆ"""
    print("ğŸ” æ­£åœ¨æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
    
    # æ£€æŸ¥åŒ…ä¾èµ–
    missing_deps = check_dependencies()
    if missing_deps:
        print("âŒ å‘ç°ç¼ºå¤±çš„ä¾èµ–åŒ…:")
        for dep in missing_deps:
            print(f"   â€¢ {dep}")
        print("\nğŸ’¡ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ç¼ºå¤±çš„ä¾èµ–:")
        print("   uv sync")
        return False
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    missing_env, warnings, env_vars = check_env_vars()
    if missing_env:
        print("âŒ å‘ç°ç¼ºå¤±çš„ç¯å¢ƒå˜é‡:")
        for env in missing_env:
            print(f"   â€¢ {env}")
        print("\nğŸ’¡ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ä»¥ä¸Šç¯å¢ƒå˜é‡")
        
        # åˆ›å»ºç¤ºä¾‹.envæ–‡ä»¶
        env_file = Path(__file__).parent / ".env"
        example_file = Path(__file__).parent / ".env.example"
        if not env_file.exists():
            if example_file.exists():
                print(f"ğŸ“ è¯·å¤åˆ¶ {example_file} ä¸º .env å¹¶é…ç½®APIå¯†é’¥")
            else:
                sample_content = """# APIé…ç½®
# Geminiçº é”™æœåŠ¡ (å¿…éœ€)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_BASE_URL=your_gemini_base_url_here

# OCRæœåŠ¡ (è‡³å°‘é…ç½®ä¸€ä¸ª)
DASHSCOPE_API_KEY=your_dashscope_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here
CUSTOM_OCR_API_KEY=your_custom_ocr_api_key_here
CUSTOM_OCR_BASE_URL=your_custom_ocr_base_url_here
"""
                env_file.write_text(sample_content)
                print(f"ğŸ“ å·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: {env_file}")
        
        return False
    
    # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
    if warnings:
        print("âš ï¸  é…ç½®æé†’:")
        for warning in warnings:
            print(f"   â€¢ {warning}")
        print("   æç¤º: å¯ä»¥é…ç½®å¤šä¸ªOCRæœåŠ¡ä»¥è·å¾—æ›´å¤šé€‰æ‹©")
    
    print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡!")
    return True

# ---------- 2. Load env & basic checks ----------
# è‡ªåŠ¨æ£€æŸ¥ä¾èµ–
if not auto_dependency_check():
    print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
    sys.exit(1)

# é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå·²ç»åœ¨check_env_varsä¸­åŠ è½½è¿‡äº†ï¼‰
load_dotenv(Path(__file__).parent / ".env")

DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY", "").strip()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL", "").strip()

# æ·»åŠ æ›´å¤šOCRæœåŠ¡çš„ç¯å¢ƒå˜é‡
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "").strip()
MISTRAL_BASE_URL = os.getenv("MISTRAL_BASE_URL", "https://api.mistral.ai/v1").strip()
CUSTOM_OCR_API_KEY = os.getenv("CUSTOM_OCR_API_KEY", "").strip()
CUSTOM_OCR_BASE_URL = os.getenv("CUSTOM_OCR_BASE_URL", "").strip()

# ---------- 3. OCR Service Architecture ----------
class OCRService(ABC):
    """OCRæœåŠ¡çš„æŠ½è±¡åŸºç±»"""
    
    def __init__(self, name: str, api_key: str, base_url: str, model: str):
        self.name = name
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.client = None
        self.supports_streaming = False  # é»˜è®¤ä¸æ”¯æŒæµå¼å¤„ç†
        if api_key and base_url:
            self.client = OpenAI(api_key=api_key, base_url=base_url)
    
    @abstractmethod
    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        pass
    
    @abstractmethod
    def process_image(self, data_uri: str) -> Tuple[str, Dict]:
        """å¤„ç†å•å¼ å›¾åƒOCR
        
        è¿”å›: (OCRæ–‡æœ¬, usageç»Ÿè®¡)
        """
        pass
    
    def process_image_streaming(self, data_uri: str, progress_callback: Callable = None) -> Tuple[str, Dict]:
        """æµå¼å¤„ç†å•å¼ å›¾åƒOCRï¼ˆé»˜è®¤å®ç°è°ƒç”¨æ™®é€šæ–¹æ³•ï¼‰
        
        å‚æ•°:
            data_uri: å›¾åƒæ•°æ®URI
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        è¿”å›: (OCRæ–‡æœ¬, usageç»Ÿè®¡)
        """
        return self.process_image(data_uri)
    
    def get_description(self) -> str:
        """è·å–æœåŠ¡æè¿°"""
        streaming_indicator = " [æµå¼]" if self.supports_streaming else ""
        return f"{self.name} ({self.model}){streaming_indicator}"


class DashScopeOCRService(OCRService):
    """é˜¿é‡Œäº‘DashScope OCRæœåŠ¡"""
    
    def __init__(self):
        super().__init__(
            name="é˜¿é‡Œäº‘DashScope",
            api_key=DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model="qwen-vl-ocr-latest"
        )
        self.supports_streaming = True  # DashScopeæ”¯æŒæµå¼å¤„ç†
    
    def is_available(self) -> bool:
        return bool(self.api_key and self.client)
    
    def process_image(self, data_uri: str) -> Tuple[str, Dict]:
        """éæµå¼å¤„ç†ï¼ˆä¸ºäº†å‘åå…¼å®¹ï¼‰"""
        return self.process_image_streaming(data_uri)
    
    def process_image_streaming(self, data_uri: str, progress_callback: Callable = None) -> Tuple[str, Dict]:
        """æµå¼å¤„ç†å›¾åƒOCR"""
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": data_uri,
                            "min_pixels": 28 * 28 * 4,
                            "max_pixels": 28 * 28 * 8192,
                        },
                    }
                ],
            }
        ]
        
        response_stream = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=True,
            stream_options={"include_usage": True},
        )
        
        ocr_text = ""
        usage_info = {}
        
        for chunk in response_stream:
            if chunk.choices and chunk.choices[0].delta.content:
                chunk_text = chunk.choices[0].delta.content
                ocr_text += chunk_text
                
                # æµå¼å›è°ƒ
                if progress_callback and chunk_text:
                    progress_callback('streaming_token', {
                        'service': 'DashScope',
                        'tokens': len(chunk_text.split()),
                        'chars': len(chunk_text)
                    })
            
            if hasattr(chunk, 'usage') and chunk.usage:
                usage_info = {
                    'input_tokens': getattr(chunk.usage, 'prompt_tokens', 0),
                    'output_tokens': getattr(chunk.usage, 'completion_tokens', 0),
                    'total_tokens': getattr(chunk.usage, 'total_tokens', 0)
                }
        
        return ocr_text, usage_info


class MistralOCRService(OCRService):
    """Mistral OCRæœåŠ¡"""
    
    def __init__(self):
        super().__init__(
            name="Mistral",
            api_key=MISTRAL_API_KEY,
            base_url=MISTRAL_BASE_URL,
            model="pixtral-12b-2409"
        )
        self.supports_streaming = True  # Mistralæ”¯æŒæµå¼å¤„ç†
    
    def is_available(self) -> bool:
        return bool(self.api_key and self.client)
    
    def process_image(self, data_uri: str) -> Tuple[str, Dict]:
        """éæµå¼å¤„ç†ï¼ˆä¸ºäº†å‘åå…¼å®¹ï¼‰"""
        return self.process_image_streaming(data_uri)
    
    def process_image_streaming(self, data_uri: str, progress_callback: Callable = None) -> Tuple[str, Dict]:
        """æµå¼å¤„ç†å›¾åƒOCR"""
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸå§‹çš„æ’ç‰ˆå’Œæ ¼å¼ã€‚åªè¾“å‡ºè¯†åˆ«çš„æ–‡å­—ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": data_uri
                        }
                    }
                ]
            }
        ]
        
        try:
            # å°è¯•æµå¼å¤„ç†
            response_stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=4000,
                temperature=0.1,
                stream=True
            )
            
            ocr_text = ""
            usage_info = {}
            
            for chunk in response_stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    chunk_text = chunk.choices[0].delta.content
                    ocr_text += chunk_text
                    
                    # æµå¼å›è°ƒ
                    if progress_callback and chunk_text:
                        progress_callback('streaming_token', {
                            'service': 'Mistral',
                            'tokens': len(chunk_text.split()),
                            'chars': len(chunk_text)
                        })
                
                if hasattr(chunk, 'usage') and chunk.usage:
                    usage_info = {
                        'input_tokens': getattr(chunk.usage, 'prompt_tokens', 0),
                        'output_tokens': getattr(chunk.usage, 'completion_tokens', 0),
                        'total_tokens': getattr(chunk.usage, 'total_tokens', 0)
                    }
            
            return ocr_text.strip(), usage_info
            
        except Exception as e:
            # å¦‚æœæµå¼å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°éæµå¼å¤„ç†
            if progress_callback:
                progress_callback('log', f"âš ï¸ Mistralæµå¼å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨éæµå¼å¤„ç†: {e}")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=4000,
                temperature=0.1
            )
            
            ocr_text = response.choices[0].message.content.strip()
            
            # æå–usageä¿¡æ¯
            usage_info = {}
            if hasattr(response, 'usage') and response.usage:
                usage_info = {
                    'input_tokens': getattr(response.usage, 'prompt_tokens', 0),
                    'output_tokens': getattr(response.usage, 'completion_tokens', 0),
                    'total_tokens': getattr(response.usage, 'total_tokens', 0)
                }
            
            return ocr_text, usage_info


class CustomOCRService(OCRService):
    """è‡ªå®šä¹‰OpenAIæ ¼å¼OCRæœåŠ¡"""
    
    def __init__(self, model_name: str = "gpt-4-vision-preview"):
        super().__init__(
            name="è‡ªå®šä¹‰OCRæœåŠ¡",
            api_key=CUSTOM_OCR_API_KEY,
            base_url=CUSTOM_OCR_BASE_URL,
            model=model_name
        )
    
    def is_available(self) -> bool:
        return bool(self.api_key and self.base_url and self.client)
    
    def process_image(self, data_uri: str) -> Tuple[str, Dict]:
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸå§‹çš„æ’ç‰ˆå’Œæ ¼å¼ã€‚åªè¾“å‡ºè¯†åˆ«çš„æ–‡å­—ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": data_uri
                        }
                    }
                ]
            }
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=4000,
            temperature=0.1
        )
        
        ocr_text = response.choices[0].message.content.strip()
        
        # æå–usageä¿¡æ¯
        usage_info = {}
        if hasattr(response, 'usage') and response.usage:
            usage_info = {
                'input_tokens': getattr(response.usage, 'prompt_tokens', 0),
                'output_tokens': getattr(response.usage, 'completion_tokens', 0),
                'total_tokens': getattr(response.usage, 'total_tokens', 0)
            }
        
        return ocr_text, usage_info


# ---------- 4. OCR Service Manager ----------
class OCRServiceManager:
    """OCRæœåŠ¡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.services = {
            "dashscope": DashScopeOCRService(),
            "mistral": MistralOCRService(),
            "custom": CustomOCRService()
        }
        
        # æ£€æŸ¥å¯ç”¨æœåŠ¡
        self.available_services = {
            key: service for key, service in self.services.items()
            if service.is_available()
        }
    
    def get_available_services(self) -> Dict[str, OCRService]:
        """è·å–å¯ç”¨çš„OCRæœåŠ¡"""
        return self.available_services
    
    def get_service(self, service_key: str) -> OCRService:
        """è·å–æŒ‡å®šçš„OCRæœåŠ¡"""
        if service_key not in self.available_services:
            raise ValueError(f"OCRæœåŠ¡ '{service_key}' ä¸å¯ç”¨")
        return self.available_services[service_key]


# åˆå§‹åŒ–OCRæœåŠ¡ç®¡ç†å™¨
ocr_manager = OCRServiceManager()

# ---------- 5. Initialize Gemini client ----------
gemini_client = OpenAI(
    api_key=GEMINI_API_KEY,
    base_url=GEMINI_BASE_URL,
)

# ---------- 6. Interactive functions ----------
def select_ocr_service() -> str:
    """äº¤äº’å¼é€‰æ‹©OCRæœåŠ¡"""
    available_services = ocr_manager.get_available_services()
    
    if not available_services:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„OCRæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®")
        return None
    
    print("\nğŸ”§ é€‰æ‹©OCRæœåŠ¡ï¼š")
    service_keys = list(available_services.keys())
    
    for i, (key, service) in enumerate(available_services.items(), 1):
        print(f"  {i}. {service.get_description()}")
    
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©OCRæœåŠ¡ (1-{len(service_keys)}): ").strip()
            choice_num = int(choice)
            
            if 1 <= choice_num <= len(service_keys):
                selected_key = service_keys[choice_num - 1]
                selected_service = available_services[selected_key]
                print(f"âœ… å·²é€‰æ‹©: {selected_service.get_description()}")
                return selected_key
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def get_terminology_files() -> List[Path]:
    """è·å–terminologyæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ä¸“æœ‰åè¯æ–‡ä»¶"""
    terminology_dir = Path("terminology")
    if not terminology_dir.exists():
        terminology_dir.mkdir()
        print("ğŸ“ å·²åˆ›å»º terminology æ–‡ä»¶å¤¹")
        return []
    
    txt_files = list(terminology_dir.glob("*.txt"))
    return txt_files


def select_terminology_file(terminology_files: List[Path]) -> Path | None:
    """äº¤äº’å¼é€‰æ‹©ä¸“æœ‰åè¯æ–‡ä»¶"""
    if not terminology_files:
        print("ğŸ“ terminology æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸“æœ‰åè¯æ–‡ä»¶ï¼Œå°†è·³è¿‡ä¸“æœ‰åè¯çº é”™åŠŸèƒ½")
        return None
    
    print("\nğŸ“ æ‰¾åˆ°ä»¥ä¸‹ä¸“æœ‰åè¯æ–‡ä»¶ï¼š")
    for i, file in enumerate(terminology_files, 1):
        print(f"  {i}. {file.name}")
    
    print(f"  {len(terminology_files) + 1}. ä¸ä½¿ç”¨ä¸“æœ‰åè¯æ–‡ä»¶")
    
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©ä¸“æœ‰åè¯æ–‡ä»¶ (1-{len(terminology_files) + 1}): ").strip()
            choice_num = int(choice)
            
            if 1 <= choice_num <= len(terminology_files):
                return terminology_files[choice_num - 1]
            elif choice_num == len(terminology_files) + 1:
                return None
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def load_terminology(terminology_file: Path | None) -> str:
    """åŠ è½½ä¸“æœ‰åè¯æ–‡ä»¶å†…å®¹"""
    if not terminology_file or not terminology_file.exists():
        return ""
    
    try:
        content = terminology_file.read_text(encoding="utf-8").strip()
        terms = [line.strip() for line in content.split('\n') if line.strip()]
        return "ã€".join(terms) if terms else ""
    except Exception as e:
        print(f"âš ï¸  è¯»å–ä¸“æœ‰åè¯æ–‡ä»¶å¤±è´¥: {e}")
        return ""


def select_preprocessing_mode():
    """äº¤äº’å¼é€‰æ‹©å›¾åƒé¢„å¤„ç†æ¨¡å¼"""
    from image_preprocessor import PreprocessingMode, create_preprocessor_config
    
    print("\nğŸ¨ é€‰æ‹©å›¾åƒé¢„å¤„ç†æ¨¡å¼ï¼š")
    modes = [
        (PreprocessingMode.NONE, "ä¸å¤„ç†", "ä¿æŒåŸå§‹å›¾åƒï¼Œé€‚åˆé«˜è´¨é‡æ‰«æä»¶"),
        (PreprocessingMode.BASIC, "åŸºç¡€å¤„ç†", "è½»é‡çº§é™å™ªå’Œé”åŒ–ï¼Œé€‚åˆä¸€èˆ¬æ–‡æ¡£"),
        (PreprocessingMode.DOCUMENT, "æ–‡æ¡£ä¼˜åŒ–", "ä¸“ä¸ºæ‰«ææ–‡æ¡£ä¼˜åŒ–ï¼ŒåŒ…å«å€¾æ–œçŸ«æ­£å’ŒäºŒå€¼åŒ–"),
        (PreprocessingMode.PHOTO, "ç…§ç‰‡ä¼˜åŒ–", "é€‚åˆæ‰‹æœºæ‹ç…§çš„æ–‡æ¡£ï¼ŒåŒ…å«é€è§†çŸ«æ­£"),
        (PreprocessingMode.AGGRESSIVE, "æ¿€è¿›å¤„ç†", "æœ€å¤§åŒ–OCRæ•ˆæœï¼Œé€‚åˆä½è´¨é‡å›¾åƒ")
    ]
    
    for i, (mode, name, desc) in enumerate(modes, 1):
        print(f"  {i}. {name} - {desc}")
    
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©é¢„å¤„ç†æ¨¡å¼ (1-{len(modes)}ï¼Œé»˜è®¤ä¸º3): ").strip()
            
            if not choice:  # é»˜è®¤é€‰æ‹©æ–‡æ¡£ä¼˜åŒ–
                choice_num = 3
            else:
                choice_num = int(choice)
            
            if 1 <= choice_num <= len(modes):
                selected_mode = modes[choice_num - 1][0]
                selected_name = modes[choice_num - 1][1]
                print(f"âœ… å·²é€‰æ‹©é¢„å¤„ç†æ¨¡å¼: {selected_name}")
                
                # åˆ›å»ºé…ç½®
                config = create_preprocessor_config(mode=selected_mode.value)
                return config
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def get_pdf_files() -> List[Path]:
    """è·å–inputæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    input_dir = Path("input")
    if not input_dir.exists():
        input_dir.mkdir()
        print("ğŸ“ å·²åˆ›å»º input æ–‡ä»¶å¤¹ï¼Œè¯·å°†PDFæ–‡ä»¶æ”¾å…¥å…¶ä¸­")
        return []
    
    pdf_files = list(input_dir.glob("*.pdf"))
    return pdf_files


def select_pdf_file(pdf_files: List[Path]) -> List[Path]:
    """äº¤äº’å¼é€‰æ‹©PDFæ–‡ä»¶"""
    if not pdf_files:
        print("âŒ input æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶")
        return []
    
    print("\nğŸ“‹ æ‰¾åˆ°ä»¥ä¸‹PDFæ–‡ä»¶ï¼š")
    for i, pdf_file in enumerate(pdf_files, 1):
        print(f"  {i}. {pdf_file.name}")
    
    print(f"  {len(pdf_files) + 1}. å…¨éƒ¨æ–‡ä»¶")
    
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶ (1-{len(pdf_files) + 1}): ").strip()
            choice_num = int(choice)
            
            if 1 <= choice_num <= len(pdf_files):
                return [pdf_files[choice_num - 1]]
            elif choice_num == len(pdf_files) + 1:
                return pdf_files
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def get_pdf_page_count(pdf_path: Path) -> int:
    """è·å–PDFæ–‡ä»¶çš„é¡µæ•°"""
    try:
        with open(pdf_path, 'rb') as file:
            reader = pypdf.PdfReader(file)
            return len(reader.pages)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–PDFæ–‡ä»¶ {pdf_path}: {e}")
        return 0


def select_page_range(pdf_path: Path) -> Tuple[int, int]:
    """äº¤äº’å¼é€‰æ‹©é¡µæ•°èŒƒå›´"""
    total_pages = get_pdf_page_count(pdf_path)
    
    if total_pages == 0:
        return 1, 1
    
    print(f"\nğŸ“„ PDFæ–‡ä»¶ '{pdf_path.name}' å…±æœ‰ {total_pages} é¡µ")
    
    while True:
        try:
            start_input = input(f"è¯·è¾“å…¥èµ·å§‹é¡µç  (1-{total_pages}ï¼Œé»˜è®¤ä¸º1): ").strip()
            start_page = int(start_input) if start_input else 1
            
            if not (1 <= start_page <= total_pages):
                print(f"âŒ èµ·å§‹é¡µç å¿…é¡»åœ¨ 1-{total_pages} ä¹‹é—´")
                continue
            
            end_input = input(f"è¯·è¾“å…¥ç»“æŸé¡µç  ({start_page}-{total_pages}ï¼Œé»˜è®¤ä¸º{start_page}): ").strip()
            end_page = int(end_input) if end_input else start_page
            
            if not (start_page <= end_page <= total_pages):
                print(f"âŒ ç»“æŸé¡µç å¿…é¡»åœ¨ {start_page}-{total_pages} ä¹‹é—´")
                continue
            
            return start_page, end_page
            
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


# ---------- 5. Helpers ----------
def pil_to_data_uri(img) -> str:
    """PIL Image -> data URI accepted by DashScope vision endpoint."""
    buf = io.BytesIO()
    img.save(buf, format="JPEG")
    b64 = base64.b64encode(buf.getvalue()).decode()
    return f"data:image/jpeg;base64,{b64}"


def get_images_for_page(pdf: str, page_zero_idx: int, enable_preprocessing: bool = True, preprocessing_config = None):
    """Convert one PDF page (0â€‘based) to a list of PIL images with optional preprocessing."""
    try:
        # è½¬æ¢PDFé¡µé¢ä¸ºå›¾åƒ
        images = convert_from_path(
            pdf,
            dpi=300,
            first_page=page_zero_idx + 1,
            last_page=page_zero_idx + 1,
        )
        
        # å¦‚æœå¯ç”¨äº†é¢„å¤„ç†ï¼Œå¯¹æ¯å¼ å›¾åƒè¿›è¡Œé¢„å¤„ç†
        if enable_preprocessing and images:
            from image_preprocessor import ImagePreprocessor, PreprocessingConfig
            
            # ä½¿ç”¨é»˜è®¤é…ç½®æˆ–ä¼ å…¥çš„é…ç½®
            if preprocessing_config is None:
                from image_preprocessor import create_preprocessor_config
                preprocessing_config = create_preprocessor_config(mode="document")
            
            preprocessor = ImagePreprocessor(preprocessing_config)
            
            processed_images = []
            for img in images:
                processed_img, stats = preprocessor.preprocess_image(img, preprocessing_config)
                processed_images.append(processed_img)
                
                # å¯é€‰ï¼šæ‰“å°é¢„å¤„ç†ç»Ÿè®¡ä¿¡æ¯
                if stats.get("operations_applied"):
                    print(f"  ğŸ“ˆ å›¾åƒé¢„å¤„ç†: {', '.join(stats['operations_applied'])}")
                    if stats.get("quality_score"):
                        print(f"  ğŸ¯ è´¨é‡è¯„åˆ†: {stats['quality_score']:.1f}/100")
            
            return processed_images
        
        return images
        
    except pdf_exc.PDFInfoNotInstalledError as e:
        raise RuntimeError(
            "pdf2image éœ€è¦ä¾èµ– popplerï¼Œè¯·å…ˆå®‰è£…ã€‚"
            "macOS: brew install poppler,  Linux: sudo apt install poppler-utils"
        ) from e


def correct_text_with_gemini(ocr_text: str, terminology_terms: str = "") -> tuple[str, dict]:
    """ä½¿ç”¨ç¬¬ä¸‰æ–¹GeminiæœåŠ¡çº é”™OCRæ–‡æœ¬å¹¶æ ¼å¼åŒ–ä¸ºmarkdown
    
    è¿”å›: (çº é”™åçš„æ–‡æœ¬, tokenä½¿ç”¨ç»Ÿè®¡)
    """
    try:
        terminology_instruction = ""
        if terminology_terms:
            terminology_instruction = f"\n\n**ä¸“æœ‰åè¯å‚è€ƒ**ï¼š{terminology_terms}\nè¯·æ ¹æ®ä¸Šè¿°ä¸“æœ‰åè¯åˆ—è¡¨çº æ­£æ–‡æœ¬ä¸­å‡ºç°çš„ç›¸å…³è¯æ±‡ã€‚"
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹OCRè¯†åˆ«çš„æ–‡æœ¬è¿›è¡Œä¸“ä¸šçš„å¤„ç†å’ŒMarkdownæ ¼å¼åŒ–ï¼š

## å¤„ç†è¦æ±‚

### 1. æ–‡æœ¬çº é”™
- ä¿®æ­£OCRè¯†åˆ«é”™è¯¯ã€é”™åˆ«å­—å’Œæ ¼å¼é—®é¢˜
- ä¿®å¤é€»è¾‘ä¸é€šé¡ºçš„åœ°æ–¹ï¼Œä¿æŒåŸæ–‡æ„æ€
- è¡¥å……ç¼ºå¤±çš„æ ‡ç‚¹ç¬¦å·å’Œæ®µè½ç»“æ„

### 2. æ™ºèƒ½ç»“æ„è¯†åˆ«
- è‡ªåŠ¨è¯†åˆ«æ–‡æ¡£çš„å±‚çº§ç»“æ„ï¼ˆæ ‡é¢˜ã€ç« èŠ‚ã€æ®µè½ç­‰ï¼‰
- è¯†åˆ«åˆ—è¡¨ã€è¡¨æ ¼ã€å¼•ç”¨ç­‰ç‰¹æ®Šå†…å®¹
- ä¿æŒåŸæ–‡çš„é€»è¾‘é¡ºåºå’Œä¿¡æ¯å®Œæ•´æ€§

### 3. ä¸“ä¸šMarkdownæ ¼å¼åŒ–
- **æ ‡é¢˜å±‚çº§**ï¼šä½¿ç”¨ # ## ### #### æ ‡è®°ä¸åŒçº§åˆ«æ ‡é¢˜
- **æ®µè½ç»“æ„**ï¼šåˆç†åˆ†æ®µï¼Œä¿æŒè‰¯å¥½çš„å¯è¯»æ€§
- **åˆ—è¡¨æ ¼å¼**ï¼šä½¿ç”¨ - æˆ– 1. æ ¼å¼åŒ–åˆ—è¡¨é¡¹
- **å¼ºè°ƒå†…å®¹**ï¼šä½¿ç”¨ **ç²—ä½“** å’Œ *æ–œä½“* çªå‡ºé‡ç‚¹
- **å¼•ç”¨æ ¼å¼**ï¼šä½¿ç”¨ > æ ‡è®°å¼•ç”¨å†…å®¹
- **ä»£ç æ ¼å¼**ï¼šä½¿ç”¨ ` æˆ– ``` æ ‡è®°ä»£ç ç‰‡æ®µ
- **è¡¨æ ¼æ ¼å¼**ï¼šè¯†åˆ«å¹¶æ ¼å¼åŒ–è¡¨æ ¼å†…å®¹

{terminology_instruction}

## è¾“å‡ºè¦æ±‚
- **ç›´æ¥è¾“å‡º**ï¼šåªè¾“å‡ºå¤„ç†åçš„Markdownæ–‡æ¡£ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜
- **è¯­æ³•è§„èŒƒ**ï¼šç¡®ä¿ç¬¦åˆæ ‡å‡†Markdownè¯­æ³•
- **ç»“æ„æ¸…æ™°**ï¼šå±‚æ¬¡åˆ†æ˜ï¼Œä¾¿äºé˜…è¯»å’Œç¼–è¾‘
- **å†…å®¹å®Œæ•´**ï¼šä¿æŒåŸæ–‡çš„æ‰€æœ‰é‡è¦ä¿¡æ¯

---

**å¾…å¤„ç†æ–‡æœ¬**ï¼š
{ocr_text}"""
        
        response = gemini_client.chat.completions.create(
            model="gemini-2.5-flash",
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.1,
            stream=False,
        )
        
        # æå–tokenä½¿ç”¨ç»Ÿè®¡
        usage_stats = {}
        if hasattr(response, 'usage') and response.usage:
            usage_stats = {
                'input_tokens': getattr(response.usage, 'prompt_tokens', 0),
                'output_tokens': getattr(response.usage, 'completion_tokens', 0),
                'total_tokens': getattr(response.usage, 'total_tokens', 0)
            }
        
        return response.choices[0].message.content.strip(), usage_stats
    except Exception as e:
        print(f"âš ï¸  Geminiçº é”™å¤±è´¥: {e}")
        return ocr_text, {}


def process_single_file(pdf_path: Path, start_page: int, end_page: int, terminology_terms: str = "", ocr_service_key: str = "dashscope", preprocessing_config = None) -> str:
    """å¤„ç†å•ä¸ªPDFæ–‡ä»¶çš„OCRå’Œçº é”™"""
    
    # è·å–é€‰æ‹©çš„OCRæœåŠ¡
    ocr_service = ocr_manager.get_service(ocr_service_key)
    
    print(f"\nğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶: {pdf_path.name}")
    print(f"ğŸ“„ é¡µæ•°èŒƒå›´: {start_page}-{end_page}")
    print(f"ğŸ”§ OCRæœåŠ¡: {ocr_service.get_description()}")
    
    # æ˜¾ç¤ºé¢„å¤„ç†é…ç½®
    if preprocessing_config:
        print(f"ğŸ¨ å›¾åƒé¢„å¤„ç†: {preprocessing_config.mode.value} æ¨¡å¼")
    else:
        print("ğŸ¨ å›¾åƒé¢„å¤„ç†: å·²ç¦ç”¨")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    out_dir = Path("ocr_output")
    out_dir.mkdir(exist_ok=True)
    
    all_pages_text = []
    pages = list(range(start_page - 1, end_page))  # è½¬æ¢ä¸º0-basedç´¢å¼•
    total_pages = len(pages)
    
    # Tokenæ¶ˆè€—ç»Ÿè®¡ - åˆ†åˆ«ç»Ÿè®¡OCRå’Œçº é”™çš„æ¶ˆè€—
    ocr_input_tokens = 0
    ocr_output_tokens = 0
    ocr_total_tokens = 0
    
    gemini_input_tokens = 0
    gemini_output_tokens = 0
    gemini_total_tokens = 0
    
    total_tokens = 0
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = tqdm(total=total_pages, desc=f"å¤„ç† {pdf_path.name}")
    
    for i, page_idx in enumerate(pages):
        try:
            # æ›´æ–°è¿›åº¦æ¡æè¿°ï¼Œæ˜¾ç¤ºå½“å‰é¡µæ•°å’Œtokenæ¶ˆè€—
            progress_bar.set_description(
                f"å¤„ç† {pdf_path.name} "
                f"[{i+1}/{total_pages}é¡µ] "
                f"[Token: {total_tokens:,}]"
            )
            
            # OCRå¤„ç†ï¼ˆå¸¦é¢„å¤„ç†ï¼‰
            enable_preprocessing = preprocessing_config is not None
            imgs = get_images_for_page(str(pdf_path), page_idx, enable_preprocessing, preprocessing_config)
            if not imgs:
                tqdm.write(f"âš ï¸  ç¬¬ {page_idx + 1} é¡µè½¬æ¢å›¾åƒå¤±è´¥ï¼Œå·²è·³è¿‡")
                progress_bar.update(1)
                continue

            data_uri = pil_to_data_uri(imgs[0])

            # ä½¿ç”¨é€‰æ‹©çš„OCRæœåŠ¡å¤„ç†å›¾åƒ
            tqdm.write(f"ğŸ” ä½¿ç”¨ {ocr_service.get_description()} è¯†åˆ«ç¬¬ {page_idx + 1} é¡µ...")
            ocr_text, ocr_usage = ocr_service.process_image(data_uri)

            # æ›´æ–°OCR tokenç»Ÿè®¡
            if ocr_usage:
                input_tokens = ocr_usage.get('input_tokens', 0)
                output_tokens = ocr_usage.get('output_tokens', 0)
                page_total_tokens = ocr_usage.get('total_tokens', input_tokens + output_tokens)
                
                ocr_input_tokens += input_tokens
                ocr_output_tokens += output_tokens
                ocr_total_tokens += page_total_tokens
                total_tokens += page_total_tokens
                
                tqdm.write(f"ğŸ“Š ç¬¬ {page_idx + 1} é¡µ OCR Tokenæ¶ˆè€—: {page_total_tokens:,} (è¾“å…¥: {input_tokens:,}, è¾“å‡º: {output_tokens:,})")

            # Geminiçº é”™
            tqdm.write(f"ğŸ”§ ä½¿ç”¨Geminiçº é”™ç¬¬ {page_idx + 1} é¡µ...")
            corrected_text, gemini_usage = correct_text_with_gemini(ocr_text, terminology_terms)
            
            # æ›´æ–°Gemini tokenç»Ÿè®¡
            if gemini_usage:
                gemini_page_input = gemini_usage.get('input_tokens', 0)
                gemini_page_output = gemini_usage.get('output_tokens', 0)
                gemini_page_total = gemini_usage.get('total_tokens', gemini_page_input + gemini_page_output)
                
                gemini_input_tokens += gemini_page_input
                gemini_output_tokens += gemini_page_output
                gemini_total_tokens += gemini_page_total
                total_tokens += gemini_page_total
                
                tqdm.write(f"ğŸ“Š ç¬¬ {page_idx + 1} é¡µ Gemini Tokenæ¶ˆè€—: {gemini_page_total:,} (è¾“å…¥: {gemini_page_input:,}, è¾“å‡º: {gemini_page_output:,})")
            
            # ä¿å­˜å•é¡µç»“æœ
            page_file = out_dir / f"{pdf_path.stem}_page_{page_idx + 1}.md"
            page_file.write_text(corrected_text, encoding="utf-8")
            
            all_pages_text.append(corrected_text)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.update(1)
            progress_bar.set_description(
                f"å¤„ç† {pdf_path.name} "
                f"[{i+1}/{total_pages}é¡µ] "
                f"[Token: {total_tokens:,}]"
            )
            
            tqdm.write(f"âœ“ ç¬¬ {page_idx + 1} é¡µå¤„ç†å®Œæˆ")
            
        except Exception as e:
            tqdm.write(f"âŒ ç¬¬ {page_idx + 1} é¡µå¤„ç†å¤±è´¥: {e}")
            progress_bar.update(1)
            continue
    
    # å…³é—­è¿›åº¦æ¡
    progress_bar.close()
    
    # æ‹¼æ¥æ‰€æœ‰é¡µé¢
    combined_text = "\n\n".join(all_pages_text)
    combined_file = out_dir / f"{pdf_path.stem}_combined.md"
    combined_file.write_text(combined_text, encoding="utf-8")
    
    print(f"âœ… æ–‡ä»¶ {pdf_path.name} å¤„ç†å®Œæˆ")
    print(f"ğŸ“ åˆå¹¶æ–‡ä»¶ä¿å­˜è‡³: {combined_file}")
    print(f"ğŸ’° Tokenæ¶ˆè€—ç»Ÿè®¡:")
    print(f"   OCR ({ocr_service.name}): {ocr_total_tokens:,} tokens (è¾“å…¥: {ocr_input_tokens:,}, è¾“å‡º: {ocr_output_tokens:,})")
    print(f"   çº é”™ (Gemini): {gemini_total_tokens:,} tokens (è¾“å…¥: {gemini_input_tokens:,}, è¾“å‡º: {gemini_output_tokens:,})")
    print(f"   æ€»è®¡: {total_tokens:,} tokens")
    
    return combined_text


def process_single_file_with_progress_callback(pdf_path: Path, start_page: int, end_page: int, terminology_terms: str = "", ocr_service_key: str = "dashscope", progress_callback: Callable = None, preprocessing_config = None):
    """
    å¸¦è¿›åº¦å›è°ƒçš„å•æ–‡ä»¶å¤„ç†å‡½æ•°
    
    å‚æ•°:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        start_page: èµ·å§‹é¡µ (1-based)
        end_page: ç»“æŸé¡µ (1-based)
        terminology_terms: ä¸“æœ‰åè¯åˆ—è¡¨
        ocr_service_key: OCRæœåŠ¡é”®å
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶(msg_type, data, **kwargs)
    
    è¿”å›: åˆå¹¶åçš„æ–‡æœ¬å†…å®¹
    """
    # è·å–OCRæœåŠ¡
    ocr_service = ocr_manager.get_service(ocr_service_key)
    if not ocr_service:
        raise ValueError(f"OCRæœåŠ¡ '{ocr_service_key}' ä¸å¯ç”¨")
    
    # è¾“å‡ºç›®å½•
    out_dir = Path("ocr_output")
    out_dir.mkdir(exist_ok=True)
    
    all_pages_text = []
    pages = list(range(start_page - 1, end_page))  # è½¬æ¢ä¸º0-basedç´¢å¼•
    total_pages = len(pages)
    
    # Tokenæ¶ˆè€—ç»Ÿè®¡ - åˆ†åˆ«ç»Ÿè®¡OCRå’Œçº é”™çš„æ¶ˆè€—
    ocr_input_tokens = 0
    ocr_output_tokens = 0
    ocr_total_tokens = 0
    
    gemini_input_tokens = 0
    gemini_output_tokens = 0
    gemini_total_tokens = 0
    
    total_tokens = 0
    
    if progress_callback:
        progress_callback('log', f"å¼€å§‹å¤„ç†æ–‡ä»¶: {pdf_path.name}")
        progress_callback('log', f"é¡µé¢èŒƒå›´: {start_page}-{end_page} (å…±{total_pages}é¡µ)")
        progress_callback('log', f"OCRæœåŠ¡: {ocr_service.get_description()}")
    
    for i, page_idx in enumerate(pages):
        try:
            # é€šçŸ¥é¡µé¢å¼€å§‹å¤„ç†
            if progress_callback:
                progress_callback('page_start', (page_idx, total_pages))
                progress_callback('log', f"ğŸ” å¤„ç†ç¬¬ {page_idx + 1} é¡µ...")
            
            # OCRå¤„ç†ï¼ˆå¸¦é¢„å¤„ç†ï¼‰
            enable_preprocessing = preprocessing_config is not None
            imgs = get_images_for_page(str(pdf_path), page_idx, enable_preprocessing, preprocessing_config)
            if not imgs:
                if progress_callback:
                    progress_callback('log', f"âš ï¸  ç¬¬ {page_idx + 1} é¡µè½¬æ¢å›¾åƒå¤±è´¥ï¼Œå·²è·³è¿‡", tag="error")
                continue

            data_uri = pil_to_data_uri(imgs[0])

            # ä½¿ç”¨é€‰æ‹©çš„OCRæœåŠ¡å¤„ç†å›¾åƒ - ä½¿ç”¨æµå¼å¤„ç†
            if progress_callback:
                progress_callback('log', f"ğŸ” ä½¿ç”¨ {ocr_service.get_description()} è¯†åˆ«ç¬¬ {page_idx + 1} é¡µ...")
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼å¤„ç†
            if hasattr(ocr_service, 'process_image_streaming') and ocr_service.supports_streaming:
                ocr_text, ocr_usage = ocr_service.process_image_streaming(data_uri, progress_callback)
            else:
                ocr_text, ocr_usage = ocr_service.process_image(data_uri)

            # æ›´æ–°OCR tokenç»Ÿè®¡
            if ocr_usage:
                input_tokens = ocr_usage.get('input_tokens', 0)
                output_tokens = ocr_usage.get('output_tokens', 0)
                page_total_tokens = ocr_usage.get('total_tokens', input_tokens + output_tokens)
                
                ocr_input_tokens += input_tokens
                ocr_output_tokens += output_tokens
                ocr_total_tokens += page_total_tokens
                total_tokens += page_total_tokens
                
                if progress_callback:
                    progress_callback('ocr_token', ocr_usage)

            # Geminiçº é”™
            if progress_callback:
                progress_callback('log', f"ğŸ”§ ä½¿ç”¨Geminiçº é”™ç¬¬ {page_idx + 1} é¡µ...")
            
            corrected_text, gemini_usage = correct_text_with_gemini_streaming(ocr_text, terminology_terms, progress_callback)
            
            # æ›´æ–°Gemini tokenç»Ÿè®¡
            if gemini_usage:
                gemini_page_input = gemini_usage.get('input_tokens', 0)
                gemini_page_output = gemini_usage.get('output_tokens', 0)
                gemini_page_total = gemini_usage.get('total_tokens', gemini_page_input + gemini_page_output)
                
                gemini_input_tokens += gemini_page_input
                gemini_output_tokens += gemini_page_output
                gemini_total_tokens += gemini_page_total
                total_tokens += gemini_page_total
                
                if progress_callback:
                    progress_callback('gemini_token', gemini_usage)
            
            # ä¿å­˜å•é¡µç»“æœ
            page_file = out_dir / f"{pdf_path.stem}_page_{page_idx + 1}.md"
            page_file.write_text(corrected_text, encoding="utf-8")
            
            all_pages_text.append(corrected_text)
            
            # é€šçŸ¥é¡µé¢å¤„ç†å®Œæˆ
            if progress_callback:
                progress_callback('page_complete', page_idx)
            
        except Exception as e:
            if progress_callback:
                progress_callback('log', f"âŒ ç¬¬ {page_idx + 1} é¡µå¤„ç†å¤±è´¥: {e}", tag="error")
            continue
    
    # æ‹¼æ¥æ‰€æœ‰é¡µé¢
    combined_text = "\n\n".join(all_pages_text)
    combined_file = out_dir / f"{pdf_path.stem}_combined.md"
    combined_file.write_text(combined_text, encoding="utf-8")
    
    if progress_callback:
        progress_callback('log', f"âœ… æ–‡ä»¶ {pdf_path.name} å¤„ç†å®Œæˆ", tag="success")
        progress_callback('log', f"ğŸ“ åˆå¹¶æ–‡ä»¶ä¿å­˜è‡³: {combined_file}")
        progress_callback('log', f"ğŸ’° æ€»Tokenæ¶ˆè€—: {total_tokens:,}", tag="token")
    
    return combined_text


def correct_text_with_gemini_streaming(text: str, terminology_terms: str = "", progress_callback: Callable = None):
    """
    ä½¿ç”¨Geminiè¿›è¡Œæ–‡æœ¬çº é”™å’Œä¼˜åŒ– - æ™ºèƒ½é€‰æ‹©å¯ç”¨æœåŠ¡
    
    å‚æ•°:
        text: éœ€è¦çº é”™çš„æ–‡æœ¬
        terminology_terms: ä¸“æœ‰åè¯åˆ—è¡¨ï¼Œç”¨äºæé«˜çº é”™å‡†ç¡®æ€§
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
    
    è¿”å›: (çº é”™åçš„æ–‡æœ¬, tokenä½¿ç”¨ç»Ÿè®¡)
    """
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not GEMINI_API_KEY or not GEMINI_BASE_URL:
        if progress_callback:
            progress_callback('log', "âš ï¸ Geminié…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡çº é”™", tag="warning")
        return text, {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}
    
    # ä¼˜å…ˆå°è¯•ç¬¬ä¸‰æ–¹æœåŠ¡ï¼ˆæ›´ç¨³å®šï¼‰
    try:
        return correct_text_with_gemini(text, terminology_terms)
    except Exception as third_party_error:
        if progress_callback:
            progress_callback('log', f"âš ï¸ ç¬¬ä¸‰æ–¹GeminiæœåŠ¡å¤±è´¥ï¼Œå°è¯•å®˜æ–¹æœåŠ¡: {third_party_error}", tag="warning")
        
        # å›é€€åˆ°å®˜æ–¹æœåŠ¡
        try:
            import google.generativeai as genai
            
            # é…ç½®Geminiå®¢æˆ·ç«¯
            genai.configure(api_key=GEMINI_API_KEY, transport='rest')
            
            # é…ç½®ç”Ÿæˆå‚æ•°
            generation_config = {
                "temperature": 0.1,
                "top_p": 0.9,
                "top_k": 40,
                "max_output_tokens": 8192,
            }
            
            # åˆ›å»ºæ¨¡å‹
            model = genai.GenerativeModel(
                model_name="gemini-2.0-flash-exp",
                generation_config=generation_config,
            )
            
            # æ„å»ºæç¤ºè¯
            terminology_prompt = f"\n\nä¸“æœ‰åè¯å‚è€ƒï¼ˆè¯·ç¡®ä¿è¿™äº›è¯æ±‡åœ¨çº é”™æ—¶ä¿æŒæ­£ç¡®ï¼‰ï¼š\n{terminology_terms}" if terminology_terms.strip() else ""
            
            prompt = f"""è¯·å¯¹ä»¥ä¸‹OCRè¯†åˆ«çš„æ–‡æœ¬è¿›è¡Œä¸“ä¸šçš„å¤„ç†å’ŒMarkdownæ ¼å¼åŒ–ï¼š

## å¤„ç†è¦æ±‚

### 1. æ–‡æœ¬çº é”™
- ä¿®æ­£OCRè¯†åˆ«é”™è¯¯ã€é”™åˆ«å­—å’Œæ ¼å¼é—®é¢˜
- ä¿®å¤é€»è¾‘ä¸é€šé¡ºçš„åœ°æ–¹ï¼Œä¿æŒåŸæ–‡æ„æ€
- è¡¥å……ç¼ºå¤±çš„æ ‡ç‚¹ç¬¦å·å’Œæ®µè½ç»“æ„

### 2. æ™ºèƒ½ç»“æ„è¯†åˆ«
- è‡ªåŠ¨è¯†åˆ«æ–‡æ¡£çš„å±‚çº§ç»“æ„ï¼ˆæ ‡é¢˜ã€ç« èŠ‚ã€æ®µè½ç­‰ï¼‰
- è¯†åˆ«åˆ—è¡¨ã€è¡¨æ ¼ã€å¼•ç”¨ç­‰ç‰¹æ®Šå†…å®¹
- ä¿æŒåŸæ–‡çš„é€»è¾‘é¡ºåºå’Œä¿¡æ¯å®Œæ•´æ€§

### 3. ä¸“ä¸šMarkdownæ ¼å¼åŒ–
- **æ ‡é¢˜å±‚çº§**ï¼šä½¿ç”¨ # ## ### #### æ ‡è®°ä¸åŒçº§åˆ«æ ‡é¢˜
- **æ®µè½ç»“æ„**ï¼šåˆç†åˆ†æ®µï¼Œä¿æŒè‰¯å¥½çš„å¯è¯»æ€§
- **åˆ—è¡¨æ ¼å¼**ï¼šä½¿ç”¨ - æˆ– 1. æ ¼å¼åŒ–åˆ—è¡¨é¡¹
- **å¼ºè°ƒå†…å®¹**ï¼šä½¿ç”¨ **ç²—ä½“** å’Œ *æ–œä½“* çªå‡ºé‡ç‚¹
- **å¼•ç”¨æ ¼å¼**ï¼šä½¿ç”¨ > æ ‡è®°å¼•ç”¨å†…å®¹
- **ä»£ç æ ¼å¼**ï¼šä½¿ç”¨ ` æˆ– ``` æ ‡è®°ä»£ç ç‰‡æ®µ
- **è¡¨æ ¼æ ¼å¼**ï¼šè¯†åˆ«å¹¶æ ¼å¼åŒ–è¡¨æ ¼å†…å®¹

{terminology_prompt}

## è¾“å‡ºè¦æ±‚
- **ç›´æ¥è¾“å‡º**ï¼šåªè¾“å‡ºå¤„ç†åçš„Markdownæ–‡æ¡£ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜
- **è¯­æ³•è§„èŒƒ**ï¼šç¡®ä¿ç¬¦åˆæ ‡å‡†Markdownè¯­æ³•
- **ç»“æ„æ¸…æ™°**ï¼šå±‚æ¬¡åˆ†æ˜ï¼Œä¾¿äºé˜…è¯»å’Œç¼–è¾‘
- **å†…å®¹å®Œæ•´**ï¼šä¿æŒåŸæ–‡çš„æ‰€æœ‰é‡è¦ä¿¡æ¯

---

**å¾…å¤„ç†æ–‡æœ¬**ï¼š
{text}"""

            if progress_callback:
                progress_callback('log', "ğŸ¤– å¼€å§‹Geminiçº é”™...")
            
            # ä½¿ç”¨éæµå¼ç”Ÿæˆ
            response = model.generate_content(prompt, stream=False)
            
            # ç›´æ¥è·å–ç”Ÿæˆçš„æ–‡æœ¬
            corrected_text = response.text
            total_chars = len(corrected_text)
            
            # è·å–usageç»Ÿè®¡
            try:
                usage_metadata = response.usage_metadata
                token_usage = {
                    'input_tokens': getattr(usage_metadata, 'prompt_token_count', 0),
                    'output_tokens': getattr(usage_metadata, 'candidates_token_count', 0),
                    'total_tokens': getattr(usage_metadata, 'total_token_count', 0)
                }
            except:
                # å¦‚æœæ— æ³•è·å–usageï¼Œä½¿ç”¨ä¼°ç®—å€¼
                estimated_input = len(prompt.split())
                estimated_output = len(corrected_text.split())
                token_usage = {
                    'input_tokens': estimated_input,
                    'output_tokens': estimated_output,
                    'total_tokens': estimated_input + estimated_output
                }
            
            if progress_callback:
                progress_callback('log', f"âœ… å®˜æ–¹Geminiçº é”™å®Œæˆï¼Œç”Ÿæˆ {total_chars} ä¸ªå­—ç¬¦")
            
            return corrected_text, token_usage
            
        except Exception as official_error:
            if progress_callback:
                progress_callback('log', f"âš ï¸ å®˜æ–¹GeminiæœåŠ¡ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡: {official_error}", tag="error")
            
            # æ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥ï¼Œè¿”å›åŸæ–‡
            return text, {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}


# ---------- 6. Main program ----------
def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ”¥ æ¬¢è¿ä½¿ç”¨å¢å¼ºç‰ˆOCRç¨‹åº")
    print("âœ¨ åŠŸèƒ½: å¤šOCRæœåŠ¡æ”¯æŒ + å›¾åƒé¢„å¤„ç† + Geminiçº é”™ + ç»“æ„è¯†åˆ« + Markdownè¾“å‡º")
    
    # é€‰æ‹©OCRæœåŠ¡
    selected_ocr_service = select_ocr_service()
    if not selected_ocr_service:
        return
    
    # é€‰æ‹©å›¾åƒé¢„å¤„ç†æ¨¡å¼
    preprocessing_config = select_preprocessing_mode()
    
    # è·å–å¹¶é€‰æ‹©ä¸“æœ‰åè¯æ–‡ä»¶
    terminology_files = get_terminology_files()
    selected_terminology_file = select_terminology_file(terminology_files)
    terminology_terms = load_terminology(selected_terminology_file)
    
    if terminology_terms:
        print(f"âœ… å·²åŠ è½½ä¸“æœ‰åè¯æ–‡ä»¶: {selected_terminology_file.name}")
    else:
        print("ğŸ“ æœªä½¿ç”¨ä¸“æœ‰åè¯æ–‡ä»¶")
    
    # è·å–PDFæ–‡ä»¶åˆ—è¡¨
    pdf_files = get_pdf_files()
    if not pdf_files:
        return
    
    # é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶
    selected_files = select_pdf_file(pdf_files)
    if not selected_files:
        return
    
    # å¤„ç†æ¯ä¸ªé€‰ä¸­çš„æ–‡ä»¶
    for pdf_path in selected_files:
        # é€‰æ‹©é¡µæ•°èŒƒå›´
        start_page, end_page = select_page_range(pdf_path)
        
        # å¤„ç†æ–‡ä»¶
        try:
            process_single_file(pdf_path, start_page, end_page, terminology_terms, selected_ocr_service, preprocessing_config)
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {pdf_path.name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            continue
    
    print("\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")
    print("ğŸ“ ç»“æœä¿å­˜åœ¨ ocr_output/ ç›®å½•ä¸­")
    print("   - å•é¡µæ–‡ä»¶: {æ–‡ä»¶å}_page_{é¡µç }.md (Markdownæ ¼å¼)")
    print("   - åˆå¹¶æ–‡ä»¶: {æ–‡ä»¶å}_combined.md (Markdownæ ¼å¼)")


if __name__ == "__main__":
    main()
