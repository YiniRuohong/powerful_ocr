#!/usr/bin/env python3
"""
é‡è¯•æœºåˆ¶å’Œæ–­ç‚¹ç»­ä¼ ç®¡ç†å™¨
æä¾›æ™ºèƒ½é‡è¯•ã€æ–­ç‚¹æ¢å¤å’Œé”™è¯¯å¤„ç†åŠŸèƒ½
"""

import time
import random
import json
import pickle
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime, timedelta
import threading
import traceback

from cache_manager import CacheManager, CacheStatus


class RetryReason(Enum):
    """é‡è¯•åŸå› æšä¸¾"""
    NETWORK_ERROR = "network_error"         # ç½‘ç»œé”™è¯¯
    API_RATE_LIMIT = "api_rate_limit"      # APIé™æµ
    API_ERROR = "api_error"                # APIé”™è¯¯
    TIMEOUT = "timeout"                    # è¶…æ—¶
    MEMORY_ERROR = "memory_error"          # å†…å­˜é”™è¯¯
    FILE_ERROR = "file_error"              # æ–‡ä»¶é”™è¯¯
    PROCESSING_ERROR = "processing_error"   # å¤„ç†é”™è¯¯
    UNKNOWN_ERROR = "unknown_error"        # æœªçŸ¥é”™è¯¯


@dataclass
class RetryConfig:
    """é‡è¯•é…ç½®"""
    max_retries: int = 3                   # æœ€å¤§é‡è¯•æ¬¡æ•°
    base_delay: float = 1.0               # åŸºç¡€å»¶è¿Ÿ(ç§’)
    max_delay: float = 300.0              # æœ€å¤§å»¶è¿Ÿ(ç§’)
    exponential_base: float = 2.0         # æŒ‡æ•°é€€é¿å€æ•°
    jitter: bool = True                   # æ·»åŠ éšæœºæŠ–åŠ¨
    retry_on_errors: List[RetryReason] = None  # å¯é‡è¯•çš„é”™è¯¯ç±»å‹
    enable_circuit_breaker: bool = True   # å¯ç”¨ç†”æ–­å™¨
    circuit_failure_threshold: int = 5    # ç†”æ–­å™¨å¤±è´¥é˜ˆå€¼
    circuit_recovery_time: int = 300      # ç†”æ–­å™¨æ¢å¤æ—¶é—´(ç§’)


@dataclass
class RetryAttempt:
    """é‡è¯•å°è¯•è®°å½•"""
    attempt_number: int
    timestamp: datetime
    error_type: RetryReason
    error_message: str
    delay_before_retry: float
    success: bool = False


@dataclass
class ProcessingState:
    """å¤„ç†çŠ¶æ€è®°å½•"""
    file_path: str
    cache_key: str
    total_pages: int
    completed_pages: List[int]
    failed_pages: List[int]
    current_page: Optional[int]
    start_time: datetime
    last_update: datetime
    retry_attempts: List[RetryAttempt]
    config: Dict[str, Any]
    ocr_service: str
    terminology_terms: str
    page_range: Tuple[int, int]
    partial_results: Dict[int, str]  # é¡µç  -> OCRç»“æœ


class CircuitBreaker:
    """ç†”æ–­å™¨å®ç°"""
    
    def __init__(self, failure_threshold: int = 5, recovery_time: int = 300):
        self.failure_threshold = failure_threshold
        self.recovery_time = recovery_time
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half_open
        self.lock = threading.Lock()
    
    def call(self, func: Callable, *args, **kwargs):
        """é€šè¿‡ç†”æ–­å™¨è°ƒç”¨å‡½æ•°"""
        with self.lock:
            if self.state == "open":
                if (datetime.now() - self.last_failure_time).seconds < self.recovery_time:
                    raise Exception("Circuit breaker is open")
                else:
                    self.state = "half_open"
            
            try:
                result = func(*args, **kwargs)
                if self.state == "half_open":
                    self.state = "closed"
                    self.failure_count = 0
                return result
            except Exception as e:
                self.failure_count += 1
                self.last_failure_time = datetime.now()
                
                if self.failure_count >= self.failure_threshold:
                    self.state = "open"
                
                raise e


class RetryManager:
    """é‡è¯•ç®¡ç†å™¨"""
    
    def __init__(self, cache_manager: CacheManager, config: RetryConfig = None):
        self.cache_manager = cache_manager
        self.config = config or RetryConfig()
        
        # è®¾ç½®é»˜è®¤å¯é‡è¯•é”™è¯¯
        if self.config.retry_on_errors is None:
            self.config.retry_on_errors = [
                RetryReason.NETWORK_ERROR,
                RetryReason.API_RATE_LIMIT,
                RetryReason.TIMEOUT,
                RetryReason.API_ERROR
            ]
        
        # æ–­ç‚¹ç»­ä¼ çŠ¶æ€å­˜å‚¨
        self.state_dir = Path("recovery_states")
        self.state_dir.mkdir(exist_ok=True)
        
        # ç†”æ–­å™¨
        self.circuit_breakers = {}
        
        self.lock = threading.RLock()
    
    def _classify_error(self, error: Exception) -> RetryReason:
        """åˆ†ç±»é”™è¯¯ç±»å‹"""
        error_str = str(error).lower()
        error_type = type(error).__name__.lower()
        
        # ç½‘ç»œç›¸å…³é”™è¯¯
        if any(keyword in error_str for keyword in ['connection', 'network', 'timeout', 'unreachable']):
            return RetryReason.NETWORK_ERROR
        
        # APIé™æµ
        if any(keyword in error_str for keyword in ['rate limit', 'too many requests', '429']):
            return RetryReason.API_RATE_LIMIT
        
        # APIé”™è¯¯
        if any(keyword in error_str for keyword in ['api', 'invalid', 'unauthorized', '401', '403', '500', '502', '503']):
            return RetryReason.API_ERROR
        
        # è¶…æ—¶é”™è¯¯
        if 'timeout' in error_str or 'timeouterror' in error_type:
            return RetryReason.TIMEOUT
        
        # å†…å­˜é”™è¯¯
        if 'memory' in error_str or 'memoryerror' in error_type:
            return RetryReason.MEMORY_ERROR
        
        # æ–‡ä»¶é”™è¯¯
        if any(keyword in error_str for keyword in ['file', 'directory', 'permission']) or 'ioerror' in error_type:
            return RetryReason.FILE_ERROR
        
        return RetryReason.UNKNOWN_ERROR
    
    def _should_retry(self, error: Exception, attempt_number: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        if attempt_number >= self.config.max_retries:
            return False
        
        error_type = self._classify_error(error)
        return error_type in self.config.retry_on_errors
    
    def _calculate_delay(self, attempt_number: int, error_type: RetryReason) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿ"""
        if error_type == RetryReason.API_RATE_LIMIT:
            # APIé™æµä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
            delay = self.config.base_delay * (self.config.exponential_base ** attempt_number) * 2
        else:
            # æ ‡å‡†æŒ‡æ•°é€€é¿
            delay = self.config.base_delay * (self.config.exponential_base ** attempt_number)
        
        # é™åˆ¶æœ€å¤§å»¶è¿Ÿ
        delay = min(delay, self.config.max_delay)
        
        # æ·»åŠ éšæœºæŠ–åŠ¨
        if self.config.jitter:
            jitter = random.uniform(0.5, 1.5)
            delay *= jitter
        
        return delay
    
    def _get_circuit_breaker(self, service_key: str) -> CircuitBreaker:
        """è·å–æœåŠ¡çš„ç†”æ–­å™¨"""
        if service_key not in self.circuit_breakers:
            self.circuit_breakers[service_key] = CircuitBreaker(
                self.config.circuit_failure_threshold,
                self.config.circuit_recovery_time
            )
        return self.circuit_breakers[service_key]
    
    def _save_processing_state(self, state: ProcessingState):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        try:
            state_file = self.state_dir / f"{state.cache_key}.json"
            state_data = asdict(state)
            
            # è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
            state_data['start_time'] = state.start_time.isoformat()
            state_data['last_update'] = state.last_update.isoformat()
            
            # è½¬æ¢é‡è¯•è®°å½•
            retry_data = []
            for attempt in state.retry_attempts:
                attempt_data = asdict(attempt)
                attempt_data['timestamp'] = attempt.timestamp.isoformat()
                attempt_data['error_type'] = attempt.error_type.value
                retry_data.append(attempt_data)
            state_data['retry_attempts'] = retry_data
            
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
    
    def _load_processing_state(self, cache_key: str) -> Optional[ProcessingState]:
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        try:
            state_file = self.state_dir / f"{cache_key}.json"
            if not state_file.exists():
                return None
            
            with open(state_file, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            
            # è½¬æ¢æ—¥æœŸæ—¶é—´
            state_data['start_time'] = datetime.fromisoformat(state_data['start_time'])
            state_data['last_update'] = datetime.fromisoformat(state_data['last_update'])
            
            # è½¬æ¢é‡è¯•è®°å½•
            retry_attempts = []
            for attempt_data in state_data['retry_attempts']:
                attempt_data['timestamp'] = datetime.fromisoformat(attempt_data['timestamp'])
                attempt_data['error_type'] = RetryReason(attempt_data['error_type'])
                retry_attempts.append(RetryAttempt(**attempt_data))
            state_data['retry_attempts'] = retry_attempts
            
            return ProcessingState(**state_data)
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def _remove_processing_state(self, cache_key: str):
        """åˆ é™¤å¤„ç†çŠ¶æ€"""
        try:
            state_file = self.state_dir / f"{cache_key}.json"
            if state_file.exists():
                state_file.unlink()
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
    
    def execute_with_retry(self, func: Callable, *args, 
                          service_key: str = "default",
                          context: str = "æ“ä½œ",
                          **kwargs) -> Any:
        """å¸¦é‡è¯•çš„å‡½æ•°æ‰§è¡Œ"""
        attempt = 0
        last_error = None
        
        while attempt <= self.config.max_retries:
            try:
                if self.config.enable_circuit_breaker:
                    circuit_breaker = self._get_circuit_breaker(service_key)
                    return circuit_breaker.call(func, *args, **kwargs)
                else:
                    return func(*args, **kwargs)
                    
            except Exception as e:
                last_error = e
                error_type = self._classify_error(e)
                
                print(f"âŒ {context}å¤±è´¥ (å°è¯• {attempt + 1}/{self.config.max_retries + 1}): {e}")
                
                if not self._should_retry(e, attempt):
                    break
                
                # è®¡ç®—å»¶è¿Ÿå¹¶ç­‰å¾…
                if attempt < self.config.max_retries:
                    delay = self._calculate_delay(attempt, error_type)
                    print(f"â³ {delay:.1f}ç§’åé‡è¯•...")
                    time.sleep(delay)
                
                attempt += 1
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        raise Exception(f"{context}å¤±è´¥ï¼Œå·²é‡è¯• {attempt} æ¬¡: {last_error}")
    
    def process_with_recovery(self, file_path: Path, config: Dict[str, Any],
                            ocr_service: str, terminology_terms: str,
                            page_range: Tuple[int, int],
                            process_func: Callable,
                            progress_callback: Callable = None) -> str:
        """å¸¦æ–­ç‚¹æ¢å¤çš„å¤„ç†"""
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self.cache_manager._generate_cache_key(
            file_path, config, ocr_service, terminology_terms, page_range
        )
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.cache_manager.get_cache(
            file_path, config, ocr_service, terminology_terms, page_range
        )
        if cached_result:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜ç»“æœ: {file_path.name}")
            return cached_result
        
        # åŠ è½½å·²æœ‰çš„å¤„ç†çŠ¶æ€
        state = self._load_processing_state(cache_key)
        
        start_page, end_page = page_range
        total_pages = end_page - start_page + 1
        
        if state is None:
            # åˆ›å»ºæ–°çš„å¤„ç†çŠ¶æ€
            state = ProcessingState(
                file_path=str(file_path),
                cache_key=cache_key,
                total_pages=total_pages,
                completed_pages=[],
                failed_pages=[],
                current_page=None,
                start_time=datetime.now(),
                last_update=datetime.now(),
                retry_attempts=[],
                config=config,
                ocr_service=ocr_service,
                terminology_terms=terminology_terms,
                page_range=page_range,
                partial_results={}
            )
            
            # æ ‡è®°ä¸ºæ­£åœ¨å¤„ç†
            self.cache_manager.mark_processing(
                file_path, config, ocr_service, terminology_terms, page_range
            )
        else:
            print(f"ğŸ”„ æ¢å¤å¤„ç†: {file_path.name} (å·²å®Œæˆ {len(state.completed_pages)}/{total_pages} é¡µ)")
        
        try:
            # å¤„ç†æ¯ä¸€é¡µ
            for page_num in range(start_page, end_page + 1):
                if page_num in state.completed_pages:
                    continue  # è·³è¿‡å·²å®Œæˆçš„é¡µé¢
                
                state.current_page = page_num
                state.last_update = datetime.now()
                self._save_processing_state(state)
                
                if progress_callback:
                    progress_callback('page_start', (page_num - start_page, total_pages))
                
                # é‡è¯•å¤„ç†å•é¡µ
                page_result = self._process_page_with_retry(
                    page_num, state, process_func, progress_callback
                )
                
                if page_result:
                    state.completed_pages.append(page_num)
                    state.partial_results[page_num] = page_result
                    if page_num in state.failed_pages:
                        state.failed_pages.remove(page_num)
                    
                    if progress_callback:
                        progress_callback('page_complete', page_num - start_page)
                else:
                    state.failed_pages.append(page_num)
                
                self._save_processing_state(state)
            
            # åˆå¹¶ç»“æœ
            if len(state.completed_pages) == total_pages:
                # æŒ‰é¡µç é¡ºåºåˆå¹¶
                results = []
                for page_num in range(start_page, end_page + 1):
                    if page_num in state.partial_results:
                        results.append(state.partial_results[page_num])
                
                combined_result = "\n\n".join(results)
                
                # ä¿å­˜åˆ°ç¼“å­˜
                processing_time = (datetime.now() - state.start_time).total_seconds()
                self.cache_manager.set_cache(
                    file_path, config, ocr_service, terminology_terms, 
                    page_range, combined_result, processing_time
                )
                
                # æ¸…ç†å¤„ç†çŠ¶æ€
                self._remove_processing_state(cache_key)
                
                print(f"âœ… å¤„ç†å®Œæˆ: {file_path.name} ({len(state.completed_pages)}/{total_pages} é¡µ)")
                return combined_result
            else:
                # éƒ¨åˆ†æˆåŠŸ
                failed_count = len(state.failed_pages)
                success_count = len(state.completed_pages)
                
                error_msg = f"éƒ¨åˆ†é¡µé¢å¤„ç†å¤±è´¥: æˆåŠŸ {success_count}/{total_pages} é¡µ, å¤±è´¥é¡µé¢: {state.failed_pages}"
                
                self.cache_manager.mark_failed(cache_key, error_msg)
                
                raise Exception(error_msg)
                
        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥: {e}"
            self.cache_manager.mark_failed(cache_key, error_msg)
            print(f"âŒ {error_msg}")
            raise
    
    def _process_page_with_retry(self, page_num: int, state: ProcessingState,
                               process_func: Callable, progress_callback: Callable = None) -> Optional[str]:
        """å¸¦é‡è¯•çš„å•é¡µå¤„ç†"""
        attempt = 0
        
        while attempt <= self.config.max_retries:
            try:
                # è°ƒç”¨å®é™…çš„å¤„ç†å‡½æ•°
                result = process_func(page_num, state.config, progress_callback)
                
                # è®°å½•æˆåŠŸçš„é‡è¯•
                if attempt > 0:
                    retry_attempt = RetryAttempt(
                        attempt_number=attempt,
                        timestamp=datetime.now(),
                        error_type=RetryReason.UNKNOWN_ERROR,
                        error_message="æˆåŠŸ",
                        delay_before_retry=0,
                        success=True
                    )
                    state.retry_attempts.append(retry_attempt)
                
                return result
                
            except Exception as e:
                error_type = self._classify_error(e)
                
                print(f"âŒ ç¬¬ {page_num} é¡µå¤„ç†å¤±è´¥ (å°è¯• {attempt + 1}/{self.config.max_retries + 1}): {e}")
                
                # è®°å½•å¤±è´¥çš„é‡è¯•
                delay = 0
                if attempt < self.config.max_retries and self._should_retry(e, attempt):
                    delay = self._calculate_delay(attempt, error_type)
                
                retry_attempt = RetryAttempt(
                    attempt_number=attempt,
                    timestamp=datetime.now(),
                    error_type=error_type,
                    error_message=str(e),
                    delay_before_retry=delay,
                    success=False
                )
                state.retry_attempts.append(retry_attempt)
                
                if not self._should_retry(e, attempt):
                    break
                
                if attempt < self.config.max_retries:
                    print(f"â³ {delay:.1f}ç§’åé‡è¯•ç¬¬ {page_num} é¡µ...")
                    time.sleep(delay)
                
                attempt += 1
        
        return None
    
    def get_recovery_status(self) -> Dict[str, Any]:
        """è·å–æ¢å¤çŠ¶æ€ä¿¡æ¯"""
        status = {
            "active_processing": [],
            "failed_processing": [],
            "total_states": 0
        }
        
        try:
            for state_file in self.state_dir.glob("*.json"):
                status["total_states"] += 1
                
                try:
                    state = self._load_processing_state(state_file.stem)
                    if state:
                        state_info = {
                            "file_path": state.file_path,
                            "progress": f"{len(state.completed_pages)}/{state.total_pages}",
                            "last_update": state.last_update.isoformat(),
                            "failed_pages": len(state.failed_pages),
                            "retry_attempts": len(state.retry_attempts)
                        }
                        
                        if state.failed_pages:
                            status["failed_processing"].append(state_info)
                        else:
                            status["active_processing"].append(state_info)
                            
                except Exception as e:
                    print(f"âš ï¸ è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥ {state_file}: {e}")
                    
        except Exception as e:
            print(f"âš ï¸ è·å–æ¢å¤çŠ¶æ€å¤±è´¥: {e}")
        
        return status
    
    def cleanup_old_states(self, max_age_hours: int = 48) -> int:
        """æ¸…ç†æ—§çš„å¤„ç†çŠ¶æ€"""
        removed_count = 0
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        try:
            for state_file in self.state_dir.glob("*.json"):
                try:
                    state = self._load_processing_state(state_file.stem)
                    if state and state.last_update < cutoff_time:
                        state_file.unlink()
                        removed_count += 1
                        print(f"ğŸ—‘ï¸ æ¸…ç†æ—§çŠ¶æ€: {state.file_path}")
                        
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†çŠ¶æ€æ–‡ä»¶å¤±è´¥ {state_file}: {e}")
                    
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ—§çŠ¶æ€å¤±è´¥: {e}")
        
        return removed_count


def create_retry_manager(cache_manager: CacheManager, 
                        max_retries: int = 3,
                        base_delay: float = 1.0) -> RetryManager:
    """åˆ›å»ºé‡è¯•ç®¡ç†å™¨çš„å·¥å‚å‡½æ•°"""
    config = RetryConfig(
        max_retries=max_retries,
        base_delay=base_delay
    )
    return RetryManager(cache_manager, config)